{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = open('/home/bilal/workspace/UmeshSejwani/variable_autoencoder/experiments/stickBreaking_vae_params_.pkl', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "def Sigmoid(x):\n",
    "    y = T.nnet.sigmoid(x)\n",
    "    return(y)\n",
    "\n",
    "def ReLU(x):\n",
    "    y = T.maximum(0.0, x)\n",
    "    return(y)\n",
    "\n",
    "def Softplus(x):\n",
    "    y = T.nnet.softplus(x)\n",
    "    return(y)\n",
    "\n",
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, input, n_in, n_out, activation, W=None, b=None):\n",
    "        self.input = input\n",
    "        self.activation = activation\n",
    "\n",
    "        if W is None:\n",
    "            W_values = np.asarray(0.01 * rng.standard_normal(size=(n_in, n_out)), dtype=theano.config.floatX)\n",
    "            W = theano.shared(value=W_values, name='W')\n",
    "        if b is None:\n",
    "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
    "            b = theano.shared(value=b_values, name='b')\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        self.output = self.activation( T.dot(self.input, self.W) + self.b )\n",
    "    \n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "class Decoder(object):\n",
    "    def __init__(self, rng, input, latent_size, out_size, activation, W_z = None, b = None):\n",
    "        self.input = input\n",
    "        self.activation = activation\n",
    "\n",
    "        # setup the params                                                                                                                          \n",
    "        if W_z is None:\n",
    "            W_values = np.asarray(0.01 * rng.standard_normal(size=(latent_size, out_size)), dtype=theano.config.floatX)\n",
    "            W_z = theano.shared(value=W_values, name='W_hid_z')\n",
    "        if b is None:\n",
    "            b_values = np.zeros((out_size,), dtype=theano.config.floatX)\n",
    "            b = theano.shared(value=b_values, name='b')\n",
    "        self.W_z = W_z\n",
    "        self.b = b\n",
    "        \n",
    "        self.pre_act_out = T.dot(self.input, self.W_z) + self.b\n",
    "        self.output = self.activation(self.pre_act_out)\n",
    "        \n",
    "        # gather parameters\n",
    "        self.params = [self.W_z, self.b]\n",
    "        \n",
    "class StickBreakingEncoder(object):\n",
    "    def __init__(self, rng, input, batch_size, in_size, latent_size, W_a = None, W_b = None, epsilon = 0.01):\n",
    "        self.srng = theano.tensor.shared_randomstreams.RandomStreams(rng.randint(999999))\n",
    "        self.input = input\n",
    "\n",
    "        # setup variational params\n",
    "        if W_a is None:\n",
    "            W_values = np.asarray(0.01 * rng.standard_normal(size=(in_size, latent_size-1)), dtype=theano.config.floatX)\n",
    "            W_a = theano.shared(value=W_values, name='W_a')\n",
    "        if W_b is None:\n",
    "            W_values = np.asarray(0.01 * rng.standard_normal(size=(in_size, latent_size-1)), dtype=theano.config.floatX)\n",
    "            W_b = theano.shared(value=W_values, name='W_b')\n",
    "        self.W_a = W_a\n",
    "        self.W_b = W_b\n",
    "\n",
    "        # compute Kumaraswamy samples\n",
    "        uniform_samples = T.cast(self.srng.uniform(size=(batch_size, latent_size-1), low=0.01, high=0.99), theano.config.floatX)\n",
    "        self.a = Softplus(T.dot(self.input, self.W_a))\n",
    "        self.b = Softplus(T.dot(self.input, self.W_b))\n",
    "        v_samples = (1-(uniform_samples**(1/self.b)))**(1/self.a)\n",
    "\n",
    "        # setup variables for recursion\n",
    "        stick_segment = theano.shared(value=np.zeros((batch_size,), dtype=theano.config.floatX), name='stick_segment')\n",
    "        remaining_stick = theano.shared(value=np.ones((batch_size,), dtype=theano.config.floatX), name='remaining_stick')\n",
    "\n",
    "        def compute_latent_vars(i, stick_segment, remaining_stick, v_samples):\n",
    "            # compute stick segment\n",
    "            stick_segment = v_samples[:,i] * remaining_stick\n",
    "            remaining_stick *= (1-v_samples[:,i])\n",
    "            return (stick_segment, remaining_stick)\n",
    "\n",
    "        (stick_segments, remaining_sticks), updates = theano.scan(fn=compute_latent_vars,\n",
    "                                                                  outputs_info=[stick_segment, remaining_stick],sequences=T.arange(latent_size-1),\n",
    "                                                                  non_sequences=[v_samples], strict=True)\n",
    "\n",
    "        self.avg_used_dims = T.mean(T.sum(remaining_sticks > epsilon, axis=0))\n",
    "        self.latent_vars = T.transpose(T.concatenate([stick_segments, T.shape_padaxis(remaining_sticks[-1, :],axis=1).T], axis=0))\n",
    "\n",
    "        self.params = [self.W_a, self.W_b]\n",
    "\n",
    "    # Kumaraswamy distribution\n",
    "    def calc_kl_divergence(self, prior_alpha, prior_beta):\n",
    "        # compute taylor expansion for E[log (1-v)] term\n",
    "        # hard-code so we don't have to use Scan()\n",
    "        kl = 1./(1+self.a*self.b) * Beta_fn(1./self.a, self.b)\n",
    "        kl += 1./(2+self.a*self.b) * Beta_fn(2./self.a, self.b)\n",
    "        kl += 1./(3+self.a*self.b) * Beta_fn(3./self.a, self.b)\n",
    "        kl += 1./(4+self.a*self.b) * Beta_fn(4./self.a, self.b)\n",
    "        kl += 1./(5+self.a*self.b) * Beta_fn(5./self.a, self.b)\n",
    "        kl += 1./(6+self.a*self.b) * Beta_fn(6./self.a, self.b)\n",
    "        kl += 1./(7+self.a*self.b) * Beta_fn(7./self.a, self.b)\n",
    "        kl += 1./(8+self.a*self.b) * Beta_fn(8./self.a, self.b)\n",
    "        kl += 1./(9+self.a*self.b) * Beta_fn(9./self.a, self.b)\n",
    "        kl += 1./(10+self.a*self.b) * Beta_fn(10./self.a, self.b)\n",
    "        kl *= (prior_beta-1)*self.b\n",
    "\n",
    "        # use another taylor approx for Digamma function\n",
    "        psi_b_taylor_approx = T.log(self.b) - 1./(2 * self.b) - 1./(12 * self.b**2)\n",
    "        kl += (self.a-prior_alpha)/self.a * (-0.57721 - psi_b_taylor_approx - 1/self.b) #T.psi(self.posterior_b)\n",
    "\n",
    "        # add normalization constants\n",
    "        kl += T.log(self.a*self.b) + T.log(Beta_fn(prior_alpha, prior_beta))\n",
    "\n",
    "        # final term\n",
    "        kl += -(self.b-1)/self.b\n",
    "\n",
    "        return kl.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.matrix('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 500), (500,))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = HiddenLayer(rng, x, 784, 500, ReLU, W=data[0], b=data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = StickBreakingEncoder(rng, x, 1, 500, 50, W_a=data[2], W_b=data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_run = theano.function(\n",
    "    inputs = [hidden.input],\n",
    "    outputs = hidden.output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_run = theano.function(\n",
    "    inputs = [encoder.input],\n",
    "    outputs = encoder.latent_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('/home/bilal/workspace/UmeshSejwani/variable_autoencoder/datasets/mnist.pkl.gz', 'rb') as f:\n",
    "    trainset, validset, testset = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_set = np.zeros((trainset[0].shape[0], 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(trainset[0].shape[0]):\n",
    "    out_hidden = hidden_run(trainset[0][i].reshape(1, 784))\n",
    "    out_encoded = encoder_run(out_hidden)\n",
    "    encoded_train_set[i] = out_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_set = np.zeros((testset[0].shape[0], 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testset[0].shape[0]):\n",
    "    out_hidden = hidden_run(trainset[0][i].reshape(1, 784))\n",
    "    out_encoded = encoder_run(out_hidden)\n",
    "    encoded_test_set[i] = out_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(encoded_train_set, trainset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.950000000000001"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.score(encoded_test_set, testset[1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(encoded_train_set, trainset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.879999999999999"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.score(encoded_test_set, testset[1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(encoded_train_set, trainset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.85"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.score(encoded_test_set, testset[1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
